{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data from file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'screen_name', 'statuses_count', 'followers_count',\n",
       "       'friends_count', 'favourites_count', 'listed_count', 'url', 'lang',\n",
       "       'time_zone', 'location', 'default_profile', 'default_profile_image',\n",
       "       'geo_enabled', 'profile_image_url', 'profile_banner_url',\n",
       "       'profile_use_background_image', 'profile_background_image_url_https',\n",
       "       'profile_text_color', 'profile_image_url_https',\n",
       "       'profile_sidebar_border_color', 'profile_background_tile',\n",
       "       'profile_sidebar_fill_color', 'profile_background_image_url',\n",
       "       'profile_background_color', 'profile_link_color', 'utc_offset',\n",
       "       'is_translator', 'follow_request_sent', 'protected', 'verified',\n",
       "       'notifications', 'description', 'contributors_enabled', 'following',\n",
       "       'created_at', 'timestamp', 'crawled_at', 'updated', 'test_set_1',\n",
       "       'test_set_2', 'bot'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "gen_acc = pd.read_csv('users.csv')\n",
    "gen_acc['bot'] = 0 \n",
    "gen_acc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "gen_acc = pd.read_csv('users.csv')\n",
    "\n",
    "gen_acc = gen_acc[['statuses_count', 'followers_count', 'friends_count', 'favourites_count', \n",
    "         'listed_count', 'default_profile', 'geo_enabled', 'profile_use_background_image', \n",
    "         'protected', 'verified']] \n",
    "\n",
    "gen_acc['bot'] = 0 \n",
    "\n",
    "fake_acc = pd.read_csv('fakeusers.csv')\n",
    "\n",
    "fake_acc = fake_acc[['statuses_count', 'followers_count', 'friends_count', 'favourites_count', \n",
    "         'listed_count', 'default_profile', 'geo_enabled', 'profile_use_background_image', \n",
    "         'protected', 'verified']] \n",
    "\n",
    "fake_acc['bot'] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging fake and genuine accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts = [gen_acc, fake_acc]\n",
    "\n",
    "accounts = pd.concat(accounts)\n",
    "\n",
    "accounts = accounts.fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x = accounts.iloc[:, 0:-1].values\n",
    "\n",
    "input_y = accounts.iloc[:, -1].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_x, input_y, test_size = 0.25, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'bootstrap': True,\n",
    "              'min_samples_leaf': 3,\n",
    "              'n_estimators': 50, \n",
    "              'min_samples_split': 10,\n",
    "              'max_features': 'sqrt',\n",
    "              'max_depth': 6,\n",
    "              'max_leaf_nodes': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9894551845342706\n"
     ]
    }
   ],
   "source": [
    "RF_model = RandomForestClassifier(**parameters)\n",
    "RF_model.fit(X_train, y_train)\n",
    "RF_predictions = RF_model.predict(X_test)\n",
    "score = accuracy_score(y_test ,RF_predictions)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(RF_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gen_tweet2 = pd.read_csv('ds/tweets.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_tweet = twt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_tweet.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_tweet.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(gen_tweet['text'])\n",
    "\n",
    "import preprocessor as p\n",
    "\n",
    "\n",
    "gen_tweet['text'] = gen_tweet['text'].apply(str)\n",
    "gen_tweet['text'] = gen_tweet['text'].apply(p.clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_tweet['text'] = gen_tweet['text'].apply(str)\n",
    "gen_tweet['text'] = gen_tweet['text'].apply(lambda x: x.lower())\n",
    "gen_tweet['text'] = gen_tweet['text'].apply(lambda x: x.strip())\n",
    "\n",
    "#tweet = ' '.join(re.sub(\"(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "# Remove URL\n",
    "import re\n",
    "gen_tweet['text'] = gen_tweet['text'].apply(lambda x:\n",
    "                                          ' '.join(re.sub(\"(\\w+:\\/\\/\\S+)\", \" \", x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_tweet['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "labels = np.ones(248533)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(gen_tweet['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(t.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_docs = t.texts_to_sequences(gen_tweet['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "# print(padded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds/glove.twitter.27B.25d.txt\n",
    "\n",
    "\n",
    "embeddings_index = dict()\n",
    "f = open('ds/glove.twitter.27B.100d.txt')\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=4, trainable=False)\n",
    "model.add(e)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=2, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet based classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishna/.virtualenvs/cv/lib/python3.5/site-packages/IPython/core/interactiveshell.py:3018: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/krishna/.virtualenvs/cv/lib/python3.5/site-packages/IPython/core/interactiveshell.py:3018: DtypeWarning: Columns (8,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/krishna/.virtualenvs/cv/lib/python3.5/site-packages/IPython/core/interactiveshell.py:3018: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gen_tweet = pd.read_csv('tweet/gen.csv')\n",
    "\n",
    "gen_tweet = gen_tweet[['retweet_count', 'reply_count', 'favorite_count', 'num_hashtags', 'num_urls', 'num_mentions', \n",
    "                     'text']]\n",
    "\n",
    "gen_tweet['bot'] = 0 \n",
    "\n",
    "f1 = pd.read_csv('tweet/f1.csv')\n",
    "f2 = pd.read_csv('tweet/f2.csv')\n",
    "f3 = pd.read_csv('tweet/f3.csv')\n",
    "\n",
    "\n",
    "f1 = f1[['retweet_count', 'reply_count', 'favorite_count', 'num_hashtags', 'num_urls', 'num_mentions', \n",
    "                     'text']]\n",
    "\n",
    "f2 = f2[['retweet_count', 'reply_count', 'favorite_count', 'num_hashtags', 'num_urls', 'num_mentions', \n",
    "                     'text']]\n",
    "\n",
    "f3 = f3[['retweet_count', 'reply_count', 'favorite_count', 'num_hashtags', 'num_urls', 'num_mentions', \n",
    "                     'text']]\n",
    "\n",
    "\n",
    "f1['bot'] = 1 \n",
    "f2['bot'] = 1 \n",
    "f3['bot'] = 1 \n",
    "\n",
    "twt = [gen_tweet, f1, f2, f3]\n",
    "\n",
    "twt = pd.concat(twt)\n",
    "\n",
    "twt = twt.fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "# gen_tweet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
